{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import six\n",
    "import more_itertools\n",
    "import glob\n",
    "import struct\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# sklearn                                                                                                                                                                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#HYPER PARAMETER\n",
    "FREQUENCY  =16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-Forward with gated activation hidden units                                                                                                                                     \n",
    "class MLP(chainer.Chain):\n",
    "   def __init__(self, n_units):\n",
    "      self.layer_name = [\"l%d\" % l for l in range(len(n_units))]\n",
    "      self.postfix = {l:[\".%s.sigm.W\" % l, \".%s.sigm.b\" % l, \\\n",
    "               \".%s.tanh.W\" % l, \".%s.tanh.b\" % l] for l in self.layer_name}\n",
    "\n",
    "      layers = {}\n",
    "      for l in range(1, len(n_units)):\n",
    "         layers[self.layer_name[l] + \"_sigmoid\"] = L.Linear(n_units[l-1], n_units[l])\n",
    "         layers[self.layer_name[l] + \"_tanh\"]    = L.Linear(n_units[l-1], n_units[l])\n",
    "\n",
    "      super(MLP, self).__init__(**layers)\n",
    "\n",
    "   def __call__(self, x):\n",
    "      h = x\n",
    "\n",
    "      for n in self.layer_name[1:]:\n",
    "         if n is not self.layer_name[-1]:\n",
    "            hs = getattr(self, \"%s_sigmoid\" %(n))(h)\n",
    "            ht = getattr(self, \"%s_tanh\" %(n))(h)\n",
    "            h = F.sigmoid(hs) * F.tanh(ht)\n",
    "         else:\n",
    "            h = getattr(self, \"%s_sigmoid\" %(n))(h)\n",
    "\n",
    "      return h\n",
    "\n",
    "def chainer_variable(x, gpu = -1):\n",
    "   if 0 <= gpu:\n",
    "      y = cuda.to_gpu(x, gpu)\n",
    "   else:\n",
    "      y = x\n",
    "   return chainer.Variable(y)\n",
    "\n",
    "\"\"\"i-vector を読み込む関数\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def writeivector(adv_x, spknum, spkrid):\n",
    "  header = []\n",
    " # drive_root_dir = \"./gdrive/My Drive/voxceb1_ivecs_test\"                                                                                                                            \n",
    "  drive_root_dir = \"./voxceb1_ivecs_test\"\n",
    "\n",
    "  for j in range(len(adv_x)):\n",
    "#    fn = drive_root_dir+\"/\"+spkrid[spknum]+\"_\"+str(spknum[j].data)+str(j)+\".ivec\"                                                                                                    \n",
    "    fn = drive_root_dir+\"/\"+spkrid_swap[int(spknum[j].data)]+\"-adv\"+str(j)+\".ivec\"\n",
    "\n",
    "    with open(fn, mode='w') as f:\n",
    "      for i in adv_x[j]:\n",
    "        f.write(str(i.data)+\"\\n\")\n",
    "#    print(fn)                                                                                                                                                                        \n",
    "    #files.download(fn)                                                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fast gradient に基づく adversarial example \\\\                                                                                                                                      \n",
    "$x^{(\\textrm{adv})} = x + \\epsilon * \\textrm{sign}(\\nabla_x \\textrm{loss}(G(x), y))$ \\\\                                                                                               \n",
    "> $x$: i-vector \\\\                                                                                                                                                                    \n",
    "> $y$: speaker label \\\\                                                                                                                                                               \n",
    "> $G(\\cdot)$: DNN \\\\                                                                                                                                                                  \n",
    "> $loss(\\cdot)$: cross entropy loss \\\\                                                                                                                                                \n",
    "> $\\epsilon$: small number                                                                                                                                                            \n",
    "\"\"\"\n",
    "def fast_gradient(G, x, y, eps = 0.01):\n",
    "\n",
    "  loss = F.softmax_cross_entropy(G(x), y)\n",
    "  loss.backward()\n",
    "  x_adv = cuda.to_cpu(x.data) + eps * np.sign(cuda.to_cpu(x.grad))\n",
    "\n",
    "  return loss, x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.mfcc抽出\n",
    "2.mfccとspkをそれぞれsplit\n",
    "3.MLPの改良(mfccで学習するように)\n",
    "4.trainingとtestをMLPに入力(mfccを用いた学習)\n",
    "5.chainerをpythonに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readaudio(audio):\n",
    "    x, fs = librosa.load(audio, sr=FREQUENCY)\n",
    "    mfcc = librosa.feature.mfcc(y=x, sr=FREQUENCY, n_mfcc=20)\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5sJomL_D0_g00002.wav\n",
      "5sJomL_D0_g00001.wav\n",
      "8jEAjG6SegY00027.wav\n",
      "8jEAjG6SegY00030.wav\n",
      "8jEAjG6SegY00004.wav\n",
      "8jEAjG6SegY00024.wav\n",
      "8jEAjG6SegY00002.wav\n",
      "8jEAjG6SegY00036.wav\n",
      "8jEAjG6SegY00023.wav\n",
      "8jEAjG6SegY00038.wav\n",
      "8jEAjG6SegY00010.wav\n",
      "8jEAjG6SegY00018.wav\n",
      "8jEAjG6SegY00037.wav\n",
      "8jEAjG6SegY00011.wav\n",
      "8jEAjG6SegY00035.wav\n",
      "8jEAjG6SegY00009.wav\n",
      "8jEAjG6SegY00006.wav\n",
      "8jEAjG6SegY00013.wav\n",
      "8jEAjG6SegY00034.wav\n",
      "8jEAjG6SegY00016.wav\n",
      "8jEAjG6SegY00005.wav\n",
      "8jEAjG6SegY00032.wav\n",
      "8jEAjG6SegY00019.wav\n",
      "8jEAjG6SegY00001.wav\n",
      "8jEAjG6SegY00028.wav\n",
      "8jEAjG6SegY00008.wav\n",
      "8jEAjG6SegY00020.wav\n",
      "8jEAjG6SegY00025.wav\n",
      "8jEAjG6SegY00021.wav\n",
      "8jEAjG6SegY00014.wav\n",
      "8jEAjG6SegY00029.wav\n",
      "8jEAjG6SegY00026.wav\n",
      "8jEAjG6SegY00031.wav\n",
      "8jEAjG6SegY00022.wav\n",
      "8jEAjG6SegY00033.wav\n",
      "8jEAjG6SegY00017.wav\n",
      "8jEAjG6SegY00015.wav\n",
      "8jEAjG6SegY00003.wav\n",
      "8jEAjG6SegY00007.wav\n",
      "8jEAjG6SegY00012.wav\n",
      "zjwijMp0Qyw00002.wav\n",
      "zjwijMp0Qyw00001.wav\n",
      "zjwijMp0Qyw00003.wav\n",
      "5r0dWxy17C800027.wav\n",
      "5r0dWxy17C800004.wav\n",
      "5r0dWxy17C800024.wav\n",
      "5r0dWxy17C800002.wav\n",
      "5r0dWxy17C800023.wav\n",
      "5r0dWxy17C800010.wav\n",
      "5r0dWxy17C800018.wav\n",
      "5r0dWxy17C800011.wav\n",
      "5r0dWxy17C800009.wav\n",
      "5r0dWxy17C800006.wav\n",
      "5r0dWxy17C800013.wav\n",
      "5r0dWxy17C800016.wav\n",
      "5r0dWxy17C800005.wav\n",
      "5r0dWxy17C800019.wav\n",
      "5r0dWxy17C800001.wav\n",
      "5r0dWxy17C800008.wav\n",
      "5r0dWxy17C800020.wav\n",
      "5r0dWxy17C800025.wav\n",
      "5r0dWxy17C800021.wav\n",
      "5r0dWxy17C800014.wav\n",
      "5r0dWxy17C800026.wav\n",
      "5r0dWxy17C800022.wav\n",
      "5r0dWxy17C800017.wav\n",
      "5r0dWxy17C800015.wav\n",
      "5r0dWxy17C800003.wav\n",
      "5r0dWxy17C800007.wav\n",
      "5r0dWxy17C800012.wav\n",
      "x6uYqmx31kE00004.wav\n",
      "x6uYqmx31kE00002.wav\n",
      "x6uYqmx31kE00010.wav\n",
      "x6uYqmx31kE00018.wav\n",
      "x6uYqmx31kE00011.wav\n",
      "x6uYqmx31kE00009.wav\n",
      "x6uYqmx31kE00006.wav\n",
      "x6uYqmx31kE00013.wav\n",
      "x6uYqmx31kE00016.wav\n",
      "x6uYqmx31kE00005.wav\n",
      "x6uYqmx31kE00019.wav\n",
      "x6uYqmx31kE00001.wav\n",
      "x6uYqmx31kE00008.wav\n",
      "x6uYqmx31kE00020.wav\n",
      "x6uYqmx31kE00014.wav\n",
      "x6uYqmx31kE00017.wav\n",
      "x6uYqmx31kE00015.wav\n",
      "x6uYqmx31kE00003.wav\n",
      "x6uYqmx31kE00007.wav\n",
      "x6uYqmx31kE00012.wav\n",
      "OXdd7Gmluts00002.wav\n",
      "OXdd7Gmluts00001.wav\n",
      "OXdd7Gmluts00003.wav\n",
      "PXmaB6Ui0fE00001.wav\n",
      "GWXujl-xAVM00027.wav\n",
      "GWXujl-xAVM00030.wav\n",
      "GWXujl-xAVM00004.wav\n",
      "GWXujl-xAVM00024.wav\n",
      "GWXujl-xAVM00051.wav\n",
      "GWXujl-xAVM00002.wav\n",
      "GWXujl-xAVM00036.wav\n",
      "GWXujl-xAVM00023.wav\n",
      "GWXujl-xAVM00040.wav\n",
      "GWXujl-xAVM00038.wav\n",
      "GWXujl-xAVM00044.wav\n",
      "GWXujl-xAVM00049.wav\n",
      "GWXujl-xAVM00010.wav\n",
      "GWXujl-xAVM00039.wav\n",
      "GWXujl-xAVM00018.wav\n",
      "GWXujl-xAVM00037.wav\n",
      "GWXujl-xAVM00011.wav\n",
      "GWXujl-xAVM00035.wav\n",
      "GWXujl-xAVM00009.wav\n",
      "GWXujl-xAVM00050.wav\n",
      "GWXujl-xAVM00055.wav\n",
      "GWXujl-xAVM00006.wav\n",
      "GWXujl-xAVM00013.wav\n",
      "GWXujl-xAVM00034.wav\n",
      "GWXujl-xAVM00016.wav\n",
      "GWXujl-xAVM00005.wav\n",
      "GWXujl-xAVM00045.wav\n",
      "GWXujl-xAVM00041.wav\n",
      "GWXujl-xAVM00032.wav\n",
      "GWXujl-xAVM00019.wav\n",
      "GWXujl-xAVM00001.wav\n",
      "GWXujl-xAVM00054.wav\n",
      "GWXujl-xAVM00028.wav\n",
      "GWXujl-xAVM00008.wav\n",
      "GWXujl-xAVM00020.wav\n",
      "GWXujl-xAVM00052.wav\n",
      "GWXujl-xAVM00046.wav\n",
      "GWXujl-xAVM00025.wav\n",
      "GWXujl-xAVM00043.wav\n",
      "GWXujl-xAVM00021.wav\n",
      "GWXujl-xAVM00014.wav\n",
      "GWXujl-xAVM00047.wav\n",
      "GWXujl-xAVM00029.wav\n",
      "GWXujl-xAVM00042.wav\n",
      "GWXujl-xAVM00026.wav\n",
      "GWXujl-xAVM00053.wav\n",
      "GWXujl-xAVM00031.wav\n",
      "GWXujl-xAVM00022.wav\n",
      "GWXujl-xAVM00033.wav\n",
      "GWXujl-xAVM00017.wav\n",
      "GWXujl-xAVM00015.wav\n",
      "GWXujl-xAVM00003.wav\n",
      "GWXujl-xAVM00048.wav\n",
      "GWXujl-xAVM00007.wav\n",
      "GWXujl-xAVM00012.wav\n",
      "OhfKF8FSq3Y00004.wav\n",
      "OhfKF8FSq3Y00002.wav\n",
      "OhfKF8FSq3Y00006.wav\n",
      "OhfKF8FSq3Y00005.wav\n",
      "OhfKF8FSq3Y00001.wav\n",
      "OhfKF8FSq3Y00008.wav\n",
      "OhfKF8FSq3Y00003.wav\n",
      "OhfKF8FSq3Y00007.wav\n",
      "OmSWVqpb-N000001.wav\n"
     ]
    }
   ],
   "source": [
    "####データ(音声)の読み込み、mfccを抽出####\n",
    "ROOT=\"/home/Yuunin/SV/id10270\"\n",
    "MFCC = []\n",
    "speaker = \"Kitt\"\n",
    "for filename in os.listdir(ROOT):\n",
    "    for utter in os.listdir(ROOT + \"/\" + filename):\n",
    "        if \".wav\" in utter:\n",
    "            print(filename + utter)\n",
    "            mfcc = readaudio(ROOT + \"/\" + filename + \"/\" + utter).flatten()\n",
    "            \n",
    "            MFCC.append(mfcc)\n",
    "#  i, s = readaudio(audio)\n",
    "#  ivec.append(i)\n",
    "#  spkr.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860\n"
     ]
    }
   ],
   "source": [
    "print(len(MFCC[157]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set()重複をなくす、sortにする\n",
    "list()でリストにする(可変、順番不動なときもある)\n",
    "sorted()でまたsortする\n",
    "enumerate()でcountする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-dacba1842971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#spkrid = { s:i for (i, s) in enumerate(sorted(list(set(spkr)))) } #iは何番目(数字), sは名前(文字)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMFCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#y = np.asarray([spkrid[s] for s in spkr], dtype=np.int16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10270\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Yuunin/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#spkrid = { s:i for (i, s) in enumerate(sorted(list(set(spkr)))) } #iは何番目(数字), sは名前(文字)\n",
    "x = np.asarray(MFCC, dtype=np.float32)\n",
    "#y = np.asarray([spkrid[s] for s in spkr], dtype=np.int16)\n",
    "y = 10270\n",
    "x_train, x_test = train_test_split(x, test_size = 0.1)\n",
    "\n",
    "print(len(ivec[0]))\n",
    "\n",
    "print(\"Data info.\")\n",
    "print(\"   %d speakers\" % len(spkrid.keys()))\n",
    "print(\"   training data: %d\" % (x_train.shape[0]))\n",
    "print(\"   test data: %d\" % (x_test.shape[0]))\n",
    "\n",
    "#spkrid_swap = {v: k for k, v in spkrid.items()} #ちょっと調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-52b13e6d0682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mivec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspkrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspkr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mivec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Yuunin/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2100\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Yuunin/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1782\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1783\u001b[0m         )\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "\"\"\"ミニバッチ学習 \\\\                                                                                                                                                                  \n",
    "$loss = loss_{std} + loss_{adv}$                                                                                                                                                      \n",
    "> $loss_{std}$: standard cross entropy loss using $x$, $y$ \\\\                                                                                                                         \n",
    "> $loss_{adv}$: adversarial loss using $x^{\\textrm{(adv)}}$, $y$ \\\\                                                                                                                   \n",
    "> $x$: i-vector \\\\                                                                                                                                                                    \n",
    "> $y$: speaker label                                                                                                                                                                  \n",
    "\"\"\"\n",
    "\n",
    "batchsize = 300 # minibatch size                                                                                                                                                      \n",
    "n_epoch = 200 # number of iterations                                                                                                                                                  \n",
    "n_hid_units = [256, 256, 512] # units of hidden layers                                                                                                                                \n",
    "eps = 0.00001 # epsilon for adversarial training                                                                                                                                      \n",
    "lr = 0.001 # learning rate                                                                                                                                                            \n",
    "gpu_id = 0 # GPU ID (0)                                                                                                                                                               \n",
    "\n",
    "# logger                                                                                                                                                                              \n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.DEBUG) #ここ調べる\n",
    "logger = logging.getLogger(__name__) #\n",
    "\n",
    "# GPU setup                                                                                                                                                                           \n",
    "cuda.get_device(gpu_id).use()\n",
    "\n",
    "# DNN (adversarial training)                                                                                                                                                          \n",
    "G_adv = MLP([x_train.shape[1]] + n_hid_units + [np.max(y_train) + 1]) #入力形式を変える\n",
    "G_adv.to_gpu()\n",
    "\n",
    "# DNN (standard training)                                                                                                                                                             \n",
    "G_std = MLP([x_train.shape[1]] + n_hid_units + [np.max(y_train) + 1]) #入力形式を変える\n",
    "G_std.to_gpu()\n",
    "\n",
    "# optimizer (adversarial training)                                                                                                                                                    \n",
    "optimizer_adv = chainer.optimizers.AdaGrad(lr = lr) #chainer to python \n",
    "optimizer_adv.setup(G_adv)\n",
    "\n",
    "# optimizer (adversarial training)                                                                                                                                                    \n",
    "optimizer_std = chainer.optimizers.AdaGrad(lr = lr) #\n",
    "optimizer_std.setup(G_std)\n",
    "\n",
    "# adversarial example generator                                                                                                                                                       \n",
    "attack = fast_gradient\n",
    "\n",
    "\n",
    "# minibatch training                                                                                                                                                                  \n",
    "for epoch in range(n_epoch):\n",
    "  perm = np.random.permutation(x_train.shape[0])\n",
    "  n_train = 0\n",
    "  loss_adv_train, loss_std_train = 0., 0.\n",
    "\n",
    "  # training                                                                                                                                                                          \n",
    "  for i in six.moves.range(0, x_train.shape[0], batchsize):\n",
    "    x = chainer_variable(x_train[perm[i:i+batchsize], :], gpu_id)\n",
    "    y = chainer_variable(y_train[perm[i:i+batchsize]], gpu_id)\n",
    "\n",
    "    G_adv.cleargrads()\n",
    "    G_std.cleargrads()\n",
    "\n",
    "    # standard training                                                                                                                                                               \n",
    "    loss = F.softmax_cross_entropy(G_std(x), y)\n",
    "    loss.backward()\n",
    "    optimizer_std.update()\n",
    "    loss_std_train += float(loss.data) * batchsize\n",
    "\n",
    "    # adversarial training\n",
    "    loss_std, x_adv2, loss_std_std, x_adv_std = attack(G_adv, x, y, eps)\n",
    "    x_adv3 = x_adv2.array\n",
    "    x_adv = x_adv3.astype(np.float32)\n",
    "    x_adv = chainer_variable(x_adv3, gpu_id)\n",
    "    loss_adv = F.softmax_cross_entropy(G_adv(x_adv), y)\n",
    "\n",
    "    G_adv.cleargrads()\n",
    "    #loss = loss_std + loss_adv                                                                                                                                                       \n",
    "    loss = loss_adv\n",
    "    loss.backward()\n",
    "    optimizer_adv.update()\n",
    "    loss_adv_train += float(loss.data) * batchsize\n",
    "\n",
    "    n_train += batchsize\n",
    "\n",
    "  loss_adv_train /= float(n_train)\n",
    "  loss_std_train /= float(n_train)\n",
    "\n",
    "  # evaluation                                                                                                                                                                        \n",
    "  x = chainer_variable(x_test, gpu_id)\n",
    "  y = chainer_variable(y_test, gpu_id)\n",
    "\n",
    "  loss_adv_test, x_adv, loss_std_std, x_adv_std  = attack(G_adv, x, y)\n",
    "  loss_adv_test_adv = F.softmax_cross_entropy(G_adv(x_adv), y)\n",
    "\n",
    "  loss_std_test, x_adv2, loss_std_std, x_adv_std = attack(G_std, x, y)\n",
    "  x_adv3 = x_adv2.array\n",
    "  x_adv = x_adv3.astype(np.float32)\n",
    "#  x_adv = chainer.cuda.to_cpu(x_adv2)                                                                                                                                                \n",
    "  x_adv = chainer_variable(x_adv, gpu_id)\n",
    "  loss_std_test_adv = F.softmax_cross_entropy(G_std(x_adv), y)\n",
    "\n",
    "if (epoch + 1) % 10 == 0:\n",
    "    logger.info(\"%3d-th epoch (adv - std): %1.3f - %1.3f (train), %1.3f - %1.3f (test), %1.3f - %1.3f (test-adv)\" %\n",
    "         (epoch + 1, loss_adv_train, loss_std_train, \\\n",
    "          float(loss_adv_test.data), float(loss_std_test.data), \\\n",
    "          float(loss_adv_test_adv.data), float(loss_std_test_adv.data)))\n",
    "\n",
    "if epoch + 1 == n_epoch:\n",
    "    writeivector(x_adv, y, spkrid_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
